{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"5J04fUqIvFSS"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/ty/Gatech/Fa2023/Deep_Learning_Final_Project/grud.py:114: RuntimeWarning: Mean of empty slice\n","  empirical_mean = np.nanmean(X, axis=1)\n","/home/ty/Gatech/Fa2023/Deep_Learning_Final_Project/grudf.py:122: RuntimeWarning: Mean of empty slice\n","  empirical_mean_1 = np.nanmean(X, axis=1)\n","  0%|          | 1/1000 [01:04<17:54:32, 64.54s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/1000, Training Loss: 0.5978, Validation Loss: 0.4754\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 2/1000 [02:09<17:54:05, 64.57s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 2/1000, Training Loss: 0.4516, Validation Loss: 0.4113\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 3/1000 [03:13<17:53:32, 64.61s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 3/1000, Training Loss: 0.4245, Validation Loss: 0.3938\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 4/1000 [04:18<17:50:09, 64.47s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 4/1000, Training Loss: 0.4170, Validation Loss: 0.3872\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 5/1000 [05:24<18:02:51, 65.30s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 5/1000, Training Loss: 0.4134, Validation Loss: 0.3832\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 6/1000 [06:28<17:51:33, 64.68s/it]"]},{"name":"stdout","output_type":"stream","text":["Epoch 6/1000, Training Loss: 0.4093, Validation Loss: 0.3796\n"]},{"name":"stderr","output_type":"stream","text":["  1%|          | 6/1000 [06:54<19:05:11, 69.13s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/ty/Gatech/Fa2023/Deep_Learning_Final_Project/GRU-DF.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ty/Gatech/Fa2023/Deep_Learning_Final_Project/GRU-DF.ipynb#W1sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m input_batch \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(new_batch[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ty/Gatech/Fa2023/Deep_Learning_Final_Project/GRU-DF.ipynb#W1sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m y_batch \u001b[39m=\u001b[39m new_batch[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:][\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ty/Gatech/Fa2023/Deep_Learning_Final_Project/GRU-DF.ipynb#W1sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m predictions \u001b[39m=\u001b[39m model(\u001b[39m*\u001b[39;49minput_batch)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ty/Gatech/Fa2023/Deep_Learning_Final_Project/GRU-DF.ipynb#W1sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(predictions, y_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ty/Gatech/Fa2023/Deep_Learning_Final_Project/GRU-DF.ipynb#W1sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n","File \u001b[0;32m~/anaconda3/envs/missing-time-series-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/anaconda3/envs/missing-time-series-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/Gatech/Fa2023/Deep_Learning_Final_Project/grudf.py:95\u001b[0m, in \u001b[0;36mGRU_DF.forward\u001b[0;34m(self, X, delta, delta_future, M, last_observation, next_observation, empirical_mean)\u001b[0m\n\u001b[1;32m     93\u001b[0m h_t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(X\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgru_d_cell\u001b[39m.\u001b[39mhidden_size, device\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     94\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(X\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)):\n\u001b[0;32m---> 95\u001b[0m     h_t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgru_d_cell(X[:, t, :], delta[:, t, :], delta_future[:, t, :], M[:, t, :], h_t, last_observation[:, t, :], next_observation[:, t, :], \n\u001b[1;32m     96\u001b[0m                           empirical_mean)\n\u001b[1;32m     97\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_layer(h_t))\n\u001b[1;32m     98\u001b[0m \u001b[39mreturn\u001b[39;00m output\u001b[39m.\u001b[39msqueeze()\n","File \u001b[0;32m~/anaconda3/envs/missing-time-series-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/anaconda3/envs/missing-time-series-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/Gatech/Fa2023/Deep_Learning_Final_Project/grudf.py:78\u001b[0m, in \u001b[0;36mGRU_DF_Cell.forward\u001b[0;34m(self, x, delta, delta_future, m, h_prev, x_last_observed, x_next_observed, empirical_mean)\u001b[0m\n\u001b[1;32m     75\u001b[0m x_hat \u001b[39m=\u001b[39m m \u001b[39m*\u001b[39m x_nan_to_num \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m m) \u001b[39m*\u001b[39m (gamma_x \u001b[39m*\u001b[39m x_last_observed \u001b[39m+\u001b[39m gamma_x_future \u001b[39m*\u001b[39m x_next_observed \u001b[39m+\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m gamma_x \u001b[39m-\u001b[39m gamma_x_future) \u001b[39m*\u001b[39m empirical_mean)\n\u001b[1;32m     76\u001b[0m h_hat \u001b[39m=\u001b[39m gamma_h \u001b[39m*\u001b[39m h_prev\n\u001b[0;32m---> 78\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msigmoid(torch\u001b[39m.\u001b[39mmatmul(x_hat, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_zx\u001b[39m.\u001b[39mt()) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mmatmul(h_hat, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_zh\u001b[39m.\u001b[39mt()) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mmatmul(m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_zm\u001b[39m.\u001b[39mt()) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_z)\n\u001b[1;32m     79\u001b[0m r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigmoid(torch\u001b[39m.\u001b[39mmatmul(x_hat, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_rx\u001b[39m.\u001b[39mt()) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mmatmul(h_hat, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_rh\u001b[39m.\u001b[39mt()) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mmatmul(m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_rm\u001b[39m.\u001b[39mt()) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_r)\n\u001b[1;32m     80\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtanh(torch\u001b[39m.\u001b[39mmatmul(x_hat, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_nx\u001b[39m.\u001b[39mt()) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mmatmul(r \u001b[39m*\u001b[39m h_hat, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_nh\u001b[39m.\u001b[39mt()) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mmatmul(m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_nm\u001b[39m.\u001b[39mt()) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_n)\n","File \u001b[0;32m~/anaconda3/envs/missing-time-series-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1682\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39m=\u001b[39m OrderedDict()\n\u001b[1;32m   1675\u001b[0m \u001b[39m# On the return type:\u001b[39;00m\n\u001b[1;32m   1676\u001b[0m \u001b[39m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m \u001b[39m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[39m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m \u001b[39m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1682\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m   1683\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m   1684\u001b[0m         _parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.model_selection import StratifiedShuffleSplit\n","import numpy as np\n","from tqdm import tqdm\n","from datasets import GRUDFdataset\n","from grudf import GRU_DF, preprocess_dataset\n","from accuracies import accuracies\n","\n","torch.manual_seed(0)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","X = np.load('data_X.npy')\n","y = np.load('data_y.npy')\n","\n","sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n","train_index, test_index = next(sss.split(X, y))\n","val_index, test_index = next(StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0).split(X[test_index], y[test_index]))\n","\n","X, delta, delta_future, M, last_observation, next_observation, empirical_mean = preprocess_dataset(X)\n","\n","train_dataset = GRUDFdataset(X[train_index], delta[train_index], delta_future[train_index],\n","                             M[train_index], last_observation[train_index], next_observation[train_index], empirical_mean[train_index], y[train_index])\n","val_dataset = GRUDFdataset(X[val_index], delta[val_index], delta_future[val_index], \n","                           M[val_index], last_observation[val_index], next_observation[val_index], empirical_mean[val_index], y[val_index])\n","test_dataset = GRUDFdataset(X[test_index], delta[test_index], delta_future[test_index], \n","                            M[test_index], last_observation[test_index], next_observation[test_index], empirical_mean[test_index], y[test_index])\n","\n","batch_size = 64\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","input_size = 5\n","hidden_size = 16\n","output_size = 1\n","lr_rate = 0.001\n","\n","model = GRU_DF(input_size=input_size, hidden_size=hidden_size)\n","model.to(device)\n","\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n","\n","early_stopping_patience = 20\n","early_stopping_counter = 0\n","best_val_loss = float('inf')\n","model_path = 'best_model_GRUDF.pth'\n","\n","num_epochs = 1000\n","for epoch in tqdm(range(num_epochs)):\n","    model.train()\n","    running_loss = 0.0\n","    for batch in train_loader:\n","        new_batch = []\n","        for item in batch:\n","            new_batch.append(item.to(device))\n","        input_batch = tuple(new_batch[:-1])\n","        y_batch = new_batch[-1:][0]\n","        predictions = model(*input_batch).squeeze()\n","        loss = criterion(predictions, y_batch)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * input_batch[0].size(0)\n","\n","    model.eval()\n","    val_loss = 0.0\n","    with torch.no_grad():\n","        for batch in val_loader:\n","            new_batch = []\n","            for item in batch:\n","                new_batch.append(item.to(device))\n","            input_batch = tuple(new_batch[:-1])\n","            y_batch = new_batch[-1:][0]\n","            predictions = model(*input_batch).squeeze()\n","            loss = criterion(predictions, y_batch)\n","            val_loss += loss.item() * input_batch[0].size(0)\n","\n","    train_loss = running_loss / len(train_loader.dataset)\n","    val_loss = val_loss / len(val_loader.dataset)\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n","\n","    scheduler.step()\n","\n","    if epoch % 10 == 0:\n","        torch.save(model.state_dict(), f'best_model_GRUDF_{epoch}.pth')\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        early_stopping_counter = 0\n","        torch.save(model.state_dict(), model_path)\n","    else:\n","        early_stopping_counter += 1\n","        if early_stopping_counter >= early_stopping_patience:\n","            print(\"Early stopping triggered\")\n","            break\n","\n","model.load_state_dict(torch.load(model_path))\n","\n","model.eval()\n","test_losses = []\n","test_labels = []\n","test_predictions = []\n","\n","with torch.no_grad():\n","    for batch in val_loader:\n","        new_batch = []\n","        for item in batch:\n","            new_batch.append(item.to(device))\n","        input_batch = tuple(new_batch[:-1])\n","        y_batch = new_batch[-1:][0]\n","        outputs = model(*input_batch).squeeze()\n","        loss = criterion(outputs, y_batch)\n","        test_losses.append(loss.item())\n","        test_predictions.extend(outputs.tolist())\n","        test_labels.extend(y_batch.tolist())\n","\n","average_test_loss = sum(test_losses) / len(test_losses)\n","print(f'Average test loss: {average_test_loss:.4f}')\n","\n","test_predictions = np.array(test_predictions)\n","test_labels = np.array(test_labels)\n","\n","accuracies(test_labels, test_predictions)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"fqRIy9dBOplT"},"outputs":[{"name":"stdout","output_type":"stream","text":["Average test loss: 0.3622\n","AUC score: 0.8319\n","Accuracy: 0.7537\n","Sensitivity: 0.7987\n","Specificity: 0.7438\n"]}],"source":["model.load_state_dict(torch.load(model_path))\n","\n","model.eval()\n","test_losses = []\n","test_labels = []\n","test_predictions = []\n","\n","with torch.no_grad():\n","    for X_batch, delta_batch, M_batch, last_observation_batch, empirical_mean_batch, y_batch in test_loader:\n","        X_batch, delta_batch, M_batch, last_observation_batch, empirical_mean_batch, y_batch \\\n","         = X_batch.to(device), delta_batch.to(device), M_batch.to(device), last_observation_batch.to(device), empirical_mean_batch.to(device), y_batch.to(device)\n","        outputs = model(X_batch, delta_batch, M_batch, last_observation_batch, empirical_mean_batch).squeeze()\n","        loss = criterion(outputs, y_batch)\n","        test_losses.append(loss.item())\n","        test_predictions.extend(outputs.tolist())\n","        test_labels.extend(y_batch.tolist())\n","\n","average_test_loss = sum(test_losses) / len(test_losses)\n","print(f'Average test loss: {average_test_loss:.4f}')\n","\n","test_predictions = np.array(test_predictions)\n","test_labels = np.array(test_labels)\n","\n","accuracies(test_labels, test_predictions)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
